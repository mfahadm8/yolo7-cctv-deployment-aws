{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/.local/lib/python3.9/site-packages (1.28.1)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.178.0.tar.gz (861 kB)\n",
      "     |████████████████████████████████| 861 kB 1.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from boto3) (0.6.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from boto3) (1.31.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/lib/python3.9/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sagemaker) (23.1.0)\n",
      "Collecting cloudpickle==2.2.1\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 7.0 MB/s             \n",
      "\u001b[?25hCollecting numpy<2.0,>=1.9.0\n",
      "  Downloading numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "     |████████████████████████████████| 18.3 MB 3.4 MB/s            \n",
      "\u001b[?25hCollecting protobuf<5.0,>=3.12\n",
      "  Downloading protobuf-4.24.1-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "     |████████████████████████████████| 311 kB 83.3 MB/s            \n",
      "\u001b[?25hCollecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sagemaker) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.9/site-packages (from sagemaker) (23.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "     |████████████████████████████████| 12.4 MB 75.8 MB/s            \n",
      "\u001b[?25hCollecting pathos\n",
      "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
      "     |████████████████████████████████| 82 kB 459 kB/s             \n",
      "\u001b[?25hCollecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting PyYAML~=6.0\n",
      "  Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.9/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/.local/lib/python3.9/site-packages (from sagemaker) (3.10.0)\n",
      "Collecting tblib==1.7.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3.9/site-packages (from botocore<1.32.0,>=1.31.1->boto3) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/.local/lib/python3.9/site-packages (from botocore<1.32.0,>=1.31.1->boto3) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/.local/lib/python3.9/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3.9/site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/lib64/python3.9/site-packages (from jsonschema->sagemaker) (0.17.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from jsonschema->sagemaker) (59.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.9/site-packages (from pandas->sagemaker) (2022.7.1)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     |████████████████████████████████| 341 kB 83.9 MB/s            \n",
      "\u001b[?25hCollecting multiprocess>=0.70.15\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 80.6 MB/s            \n",
      "\u001b[?25hCollecting ppft>=1.7.6.7\n",
      "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 9.3 MB/s             \n",
      "\u001b[?25hCollecting pox>=0.3.3\n",
      "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
      "Collecting dill>=0.3.7\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "     |████████████████████████████████| 115 kB 81.6 MB/s            \n",
      "\u001b[?25hCollecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Using legacy 'setup.py install' for sagemaker, since package 'wheel' is not installed.\n",
      "Installing collected packages: dill, tzdata, ppft, pox, numpy, multiprocess, contextlib2, tblib, smdebug-rulesconfig, schema, PyYAML, protobuf, pathos, pandas, google-pasta, cloudpickle, sagemaker\n",
      "    Running setup.py install for sagemaker ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyYAML-6.0.1 cloudpickle-2.2.1 contextlib2-21.6.0 dill-0.3.7 google-pasta-0.2.0 multiprocess-0.70.15 numpy-1.25.2 pandas-2.0.3 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 protobuf-4.24.1 sagemaker-2.178.0 schema-0.7.5 smdebug-rulesconfig-1.0.1 tblib-1.7.0 tzdata-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "async-inference\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import boto3\n",
    "import datetime\n",
    "import time\n",
    "from time import strftime,gmtime\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import sys\n",
    "import io\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")\n",
    "sns_client = boto3.client('sns')\n",
    "region = boto_session.region_name\n",
    "bucket=\"lightsketch-models-188775091215\"\n",
    "prefix = 'async-inference'\n",
    "\n",
    "print(region)\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detached policy: arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\n",
      "Detached policy: arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Specify the role name\n",
    "role_name = 'SageMaker-Role'\n",
    "\n",
    "# Create an IAM client\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "try:\n",
    "    response = iam_client.list_attached_role_policies(RoleName=role_name)\n",
    "    attached_policies = response['AttachedPolicies']\n",
    "    # Detach policies\n",
    "    for policy in attached_policies:\n",
    "        policy_arn = policy['PolicyArn']\n",
    "        iam_client.detach_role_policy(RoleName=role_name, PolicyArn=policy_arn)\n",
    "        print(f\"Detached policy: {policy_arn}\")\n",
    "\n",
    "# Delete inline policies\n",
    "    iam_client.delete_role(RoleName=role_name)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker role created successfully: arn:aws:iam::188775091215:role/SageMaker-Role\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonSageMakerFullAccess to the role.\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonS3FullAccess to the role.\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonSNSFullAccess to the role.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Specify the role name\n",
    "role_name = 'SageMaker-Role'\n",
    "\n",
    "# Managed policies for SageMaker\n",
    "managed_policy_arns = [\n",
    "    'arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonSNSFullAccess'\n",
    "]\n",
    "\n",
    "# Create an IAM client\n",
    "iam_client = boto3.client('iam')\n",
    "    \n",
    "# Create the role\n",
    "try:\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"sagemaker.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    create_role_response = iam_client.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    "    )\n",
    "    print(\"SageMaker role created successfully:\", create_role_response['Role']['Arn'])\n",
    "    \n",
    "    # Attach managed policies to the role\n",
    "    for policy_arn in managed_policy_arns:\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=policy_arn\n",
    "        )\n",
    "        print(f\"Attached policy {policy_arn} to the role.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Role with the same name already exists.\")\n",
    "    else:\n",
    "        print(\"Error creating SageMaker role:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = create_role_response['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn=\"arn:aws:iam::188775091215:role/SageMaker-Role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "# Import packages\n",
    "import boto3 # AWS Session Management\n",
    "import sagemaker # SageMaker SDK\n",
    "\n",
    "model = PyTorchModel(entry_point='inference.py',\n",
    "                     model_data=\"s3://lightsketch-models-188775091215/models/model.tar.gz\",\n",
    "                     framework_version='1.12',\n",
    "                     py_version='py38',\n",
    "                     role=role_arn\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-ErrorTopic\")\n",
    "error_topic= response['TopicArn']\n",
    "print(error_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-SuccessTopic\")\n",
    "success_topic = response['TopicArn']\n",
    "print(success_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:PipelineApproval'}]\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.list_topics()\n",
    "topics = response[\"Topics\"]\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "email_id = 'mfahadm8@gmail.com'\n",
    "email_sub_1 = sns_client.subscribe(\n",
    "    TopicArn=success_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n",
    "\n",
    "email_sub_2 = sns_client.subscribe(\n",
    "    TopicArn=error_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from datetime import datetime\n",
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "INSTANCE_TYPE = 'ml.c5.xlarge'\n",
    "ENDPOINT_NAME = 'yolov7-pytorch-' + str(datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f'))\n",
    "\n",
    "async_interface_config=AsyncInferenceConfig(\n",
    "      output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "      notification_config={\n",
    "                        \"SuccessTopic\": success_topic,\n",
    "                        \"ErrorTopic\": error_topic,\n",
    "                        })\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                         instance_type=INSTANCE_TYPE,\n",
    "                         deserializer=JSONDeserializer(),\n",
    "                         endpoint_name=ENDPOINT_NAME,\n",
    "                         env={\n",
    "                            'TS_MAX_REQUEST_SIZE': '100000000',\n",
    "                            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "                            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'  \n",
    "                         },\n",
    "                         async_inference_config=async_interface_config\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12-cpu-py38\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "deploy_instance_type = 'ml.c5.xlarge'\n",
    "pytorch_inference_image_uri = retrieve('pytorch',\n",
    "                                       region,\n",
    "                                       version='1.12',\n",
    "                                       py_version='py38',\n",
    "                                       instance_type = deploy_instance_type,\n",
    "                                       accelerator_type=None,\n",
    "                                       image_scope='inference')\n",
    "print(pytorch_inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12-cpu-py38\n",
      "ball-tracking-yolo7-1692464054\n"
     ]
    }
   ],
   "source": [
    "container = pytorch_inference_image_uri\n",
    "model_artifact=\"s3://lightsketch-models-188775091215/models/model.tar.gz\"\n",
    "model_name = 'ball-tracking-yolo7-{0}'.format(str(int(time.time())))\n",
    "print(container)\n",
    "print(model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role_arn,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_artifact,\n",
    "        'Mode': 'SingleModel',\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL':'20',\n",
    "            'SAGEMAKER_PROGRAM':'inference.py',\n",
    "            'SAGEMAKER_REGION':region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY':'/opt/ml/model/code',\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "    },    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-ErrorTopic\")\n",
    "error_topic= response['TopicArn']\n",
    "print(error_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-SuccessTopic\")\n",
    "success_topic = response['TopicArn']\n",
    "print(success_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:PipelineApproval'}]\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.list_topics()\n",
    "topics = response[\"Topics\"]\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "email_id = 'mfahadm8@gmail.com'\n",
    "email_sub_1 = sns_client.subscribe(\n",
    "    TopicArn=success_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n",
    "\n",
    "email_sub_2 = sns_client.subscribe(\n",
    "    TopicArn=error_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball-tracking-yolo7-1692461840\n",
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:188775091215:endpoint-config/pytorchasyncendpointconfig-2023-08-19-16-43-48\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"PyTorchAsyncEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.c5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{prefix}/output\",\n",
    "            #  Optionally specify Amazon SNS topics\n",
    "            \"NotificationConfig\": {\n",
    "              \"SuccessTopic\": success_topic,\n",
    "              \"ErrorTopic\": error_topic,\n",
    "            }\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint: arn:aws:sagemaker:us-east-1:188775091215:endpoint/sm-2023-08-19-16-43-51\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"sm-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print(f\"Creating Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke asynchronous endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_1_s3_location)\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_output(output_location):\n",
    "    output_url = urllib.parse.urlparse(output_location)\n",
    "    bucket = output_url.netloc\n",
    "    key = output_url.path[1:]\n",
    "    while True:\n",
    "        try:\n",
    "            return sm_session.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                print(\"waiting for output...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_output(output_location)\n",
    "print(f\"Output size in bytes: {((sys.getsizeof(output)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
