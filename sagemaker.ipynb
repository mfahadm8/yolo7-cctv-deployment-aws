{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install boto3 sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "async-inference\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import boto3\n",
    "import datetime\n",
    "import time\n",
    "from time import strftime,gmtime\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import sys\n",
    "import io\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "sm_client = boto_session.client(\"sagemaker\")\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")\n",
    "sns_client = boto3.client('sns')\n",
    "region = boto_session.region_name\n",
    "bucket=\"lightsketch-models-188775091215\"\n",
    "prefix = 'async-inference'\n",
    "\n",
    "print(region)\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detached policy: arn:aws:iam::aws:policy/AmazonSNSFullAccess\n",
      "Detached policy: arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\n",
      "Detached policy: arn:aws:iam::aws:policy/AmazonS3FullAccess\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Specify the role name\n",
    "role_name = 'SageMaker-Role'\n",
    "\n",
    "# Create an IAM client\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "try:\n",
    "    response = iam_client.list_attached_role_policies(RoleName=role_name)\n",
    "    attached_policies = response['AttachedPolicies']\n",
    "    # Detach policies\n",
    "    for policy in attached_policies:\n",
    "        policy_arn = policy['PolicyArn']\n",
    "        iam_client.detach_role_policy(RoleName=role_name, PolicyArn=policy_arn)\n",
    "        print(f\"Detached policy: {policy_arn}\")\n",
    "\n",
    "# Delete inline policies\n",
    "    iam_client.delete_role(RoleName=role_name)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker role created successfully: arn:aws:iam::188775091215:role/SageMaker-Role\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonSageMakerFullAccess to the role.\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonS3FullAccess to the role.\n",
      "Attached policy arn:aws:iam::aws:policy/AmazonSNSFullAccess to the role.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Specify the role name\n",
    "role_name = 'SageMaker-Role'\n",
    "\n",
    "# Managed policies for SageMaker\n",
    "managed_policy_arns = [\n",
    "    'arn:aws:iam::aws:policy/AmazonSageMakerFullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    'arn:aws:iam::aws:policy/AmazonSNSFullAccess'\n",
    "]\n",
    "\n",
    "# Create an IAM client\n",
    "iam_client = boto3.client('iam')\n",
    "    \n",
    "# Create the role\n",
    "try:\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"sagemaker.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    create_role_response = iam_client.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    "    )\n",
    "    print(\"SageMaker role created successfully:\", create_role_response['Role']['Arn'])\n",
    "    \n",
    "    # Attach managed policies to the role\n",
    "    for policy_arn in managed_policy_arns:\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=policy_arn\n",
    "        )\n",
    "        print(f\"Attached policy {policy_arn} to the role.\")\n",
    "\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Role with the same name already exists.\")\n",
    "    else:\n",
    "        print(\"Error creating SageMaker role:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = create_role_response['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn=\"arn:aws:iam::188775091215:role/SageMaker-Role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "# Import packages\n",
    "import boto3 # AWS Session Management\n",
    "import sagemaker # SageMaker SDK\n",
    "\n",
    "model = PyTorchModel(entry_point='inference.py',\n",
    "                     model_data=\"s3://lightsketch-models-188775091215/models/model.tar.gz\",\n",
    "                     framework_version='1.12',\n",
    "                     py_version='py38',\n",
    "                     role=role_arn\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-ErrorTopic\")\n",
    "error_topic= response['TopicArn']\n",
    "print(error_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.create_topic(Name=\"Async-ML-SuccessTopic\")\n",
    "success_topic = response['TopicArn']\n",
    "print(success_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-ErrorTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:Async-ML-SuccessTopic'}, {'TopicArn': 'arn:aws:sns:us-east-1:188775091215:PipelineApproval'}]\n"
     ]
    }
   ],
   "source": [
    "response = sns_client.list_topics()\n",
    "topics = response[\"Topics\"]\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "email_id = 'mfahadm8@gmail.com'\n",
    "email_sub_1 = sns_client.subscribe(\n",
    "    TopicArn=success_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n",
    "\n",
    "email_sub_2 = sns_client.subscribe(\n",
    "    TopicArn=error_topic,\n",
    "    Protocol='email',\n",
    "    Endpoint=email_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from datetime import datetime\n",
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "INSTANCE_TYPE = 'ml.c5.xlarge'\n",
    "ENDPOINT_NAME = 'yolov7-rt-' + str(datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f'))\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1,\n",
    "                         instance_type=INSTANCE_TYPE,\n",
    "                         deserializer=JSONDeserializer(),\n",
    "                         endpoint_name=ENDPOINT_NAME,\n",
    "                         env={\n",
    "                            'TS_MAX_REQUEST_SIZE': '100000000',\n",
    "                            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "                            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'  \n",
    "                         }\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### realtime testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_data = open('temp/20200616_VB_trim.mp4', 'rb')\n",
    "sm_runtime = boto3.Session().client('sagemaker-runtime',region_name=\"us-east-1\")\n",
    "r = sm_runtime.invoke_endpoint(EndpointName=\"realtime\", Body=feed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Endpoint Creation Step By Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12-cpu-py38\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "deploy_instance_type = 'ml.c5.xlarge'\n",
    "pytorch_inference_image_uri = retrieve('pytorch',\n",
    "                                       region,\n",
    "                                       version='1.12',\n",
    "                                       py_version='py38',\n",
    "                                       instance_type = deploy_instance_type,\n",
    "                                       accelerator_type=None,\n",
    "                                       image_scope='inference')\n",
    "print(pytorch_inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.12-cpu-py38\n",
      "ball-tracking-yolo7-1692830551\n"
     ]
    }
   ],
   "source": [
    "container = pytorch_inference_image_uri\n",
    "model_artifact=\"s3://lightsketch-models-188775091215/models/model.tar.gz\"\n",
    "model_name = 'ball-tracking-yolo7-{0}'.format(str(int(time.time())))\n",
    "print(container)\n",
    "print(model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role_arn,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_artifact,\n",
    "        'Mode': 'SingleModel',\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL':'20',\n",
    "            'SAGEMAKER_PROGRAM':'inference.py',\n",
    "            'SAGEMAKER_REGION':region,\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY':'/opt/ml/model/code',\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "    },    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ball-tracking-yolo7-1692830551\n",
      "Created EndpointConfig: arn:aws:sagemaker:us-east-1:188775091215:endpoint-config/pytorchasyncendpointconfig-2023-08-23-22-47-09\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"PyTorchAsyncEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.c5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{prefix}/output\",\n",
    "            #  Optionally specify Amazon SNS topics\n",
    "            \"NotificationConfig\": {\n",
    "              \"SuccessTopic\": success_topic,\n",
    "              \"ErrorTopic\": error_topic,\n",
    "            }\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint: arn:aws:sagemaker:us-east-1:188775091215:endpoint/sm-2023-08-23-22-47-14\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = f\"sm-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print(f\"Creating Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for endpoint to create...\n",
      "Endpoint Status: InService\n"
     ]
    }
   ],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=\"test\", \n",
    "    InputLocation=\"s3://lightsketch-models-188775091215/models/20200616_VB_trim.mp4\")\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_name)\n",
    "endpoint_config_name = f\"PyTorchAsyncEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.c5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": f\"s3://{bucket}/{prefix}/output\",\n",
    "            #  Optionally specify Amazon SNS topics\n",
    "            \"NotificationConfig\": {\n",
    "              \"SuccessTopic\": success_topic,\n",
    "              \"ErrorTopic\": error_topic,\n",
    "            }\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"sm-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_response = sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print(f\"Creating Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke asynchronous endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_1_s3_location)\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_output(output_location):\n",
    "    output_url = urllib.parse.urlparse(output_location)\n",
    "    bucket = output_url.netloc\n",
    "    key = output_url.path[1:]\n",
    "    while True:\n",
    "        try:\n",
    "            return sm_session.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                print(\"waiting for output...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_output(output_location)\n",
    "print(f\"Output size in bytes: {((sys.getsizeof(output)))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
